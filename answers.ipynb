{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Respuestas_Tarea_2_CC6204_2020",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEJLFL-H5axT"
      },
      "source": [
        "# Task 2: Backpropagation, gradient descend and training <br/> CC6204 Deep Learning, Universidad de Chile  <br/>\n",
        "## Name: Humberto Rodrigues "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rN1E2MUXDSn"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Autocorrect library\n",
        "!pip install -U \"git+https://github.com/dccuchile/CC6204.git@master#egg=cc6204&subdirectory=autocorrect\"\n",
        "from timeit import default_timer as timer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVhyLn9G5NJV"
      },
      "source": [
        "# importamos las herramientas del curso\n",
        "from cc6204 import AutoCorrect, FailedTest\n",
        "\n",
        "# ingresa el host y port que posteamos en u-cursos\n",
        "corrector = AutoCorrect(host=\"cc6204.dcc.uchile.cl\", port=443)\n",
        "\n",
        "# anota el token que te daremos en u-cursos\n",
        "token = \"]ye/Ox;nsz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg8i3agyXDSr"
      },
      "source": [
        "# Parte 1: Preliminares: funciones de activación y función de error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbzcMAkOXDSr"
      },
      "source": [
        "## 1a) Derivando las funciones de activación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcybEP7fXDSs"
      },
      "source": [
        "Escribe acá tus respuestas para las derivadas de cada función de activación.\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial\\ \\text{relu}(x)}{\\partial x} = \\ldots \\\\\n",
        "\\end{equation}\n",
        "<br>\n",
        "\n",
        "\\begin{eqnarray}\n",
        "\\frac{\\partial\\ \\text{swish}(x, \\ldots)}{\\partial x} & = & \\ldots \\\\\n",
        "\\frac{\\partial\\ \\text{swish}(x, \\ldots)}{\\partial \\ldots} & = & \\ldots \\\\\n",
        "\\end{eqnarray}\n",
        "<br>\n",
        "\n",
        "\\begin{eqnarray}\n",
        "\\frac{\\partial\\ \\text{celu}(x, \\ldots)}{\\partial x} & = & \\ldots \\\\\n",
        "\\frac{\\partial\\ \\text{celu}(x, \\ldots)}{\\partial \\ldots} & = & \\ldots \\\\\n",
        "\\end{eqnarray}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QfQVggvNuv9"
      },
      "source": [
        "# Más adelante en la tarea necesitaremos usar las funciones de activación \n",
        "# que implementaste en la Tarea 1 y sus derivadas.\n",
        "# Acá implementa las derivadas de las funciones de activación\n",
        "\n",
        "# Una forma de implementarlas (tal vez no la mejor) es reutilizando la misma función\n",
        "def sig(T, gradient=False):\n",
        "  if gradient:\n",
        "    sigT = sig(T)\n",
        "    return sigT * (1 - sigT)\n",
        "  return torch.reciprocal(1 + torch.exp(-1 * T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifPp_c1eXDSt"
      },
      "source": [
        "## 1b) Entropía Cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4wXj3AUXDSu"
      },
      "source": [
        "# Tu código acá\n",
        "def CELoss(Q, P, estable=True, epsilon=1e-8):\n",
        "  # Q y P: representan distribuciones de probabilidad discreta  \n",
        "  #        (mediante matrices con las mismas dimensiones)\n",
        "  # estable y epsilon: nos permiten lograr estabilidad numérica cuando \n",
        "  #       intentamos computar el logaritmo de valores muy pequeños.\n",
        "  #       epsilon limitará el valor mínimo del valor original cuando estable=True\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrjGpVdg4xi1"
      },
      "source": [
        "# Tests del API del curso\n",
        "for test in ['small', 'estable', 'eps', 'no-estable']:\n",
        "  # Obtengamos dos distribuciones de probabilidad y los parametros estable y epsilon\n",
        "  Q, P, estable, eps = corrector.get_test_data(homework=2, question=\"1b\", test=test, token=token)\n",
        "  # Corramos tu implementacion de CELoss para ver como se comporta\n",
        "  s = timer()\n",
        "  result = CELoss(Q=torch.Tensor(Q), P=torch.Tensor(P), estable=estable, epsilon=eps)\n",
        "  t = timer() - s\n",
        "\n",
        "  # Veamos si todo fue OK :)\n",
        "  # Si el Test te falla algunas veces por [time], puedes hacer time=0 ;-)\n",
        "  corrector.sumbit(homework=2, question=\"1b\", test=test, token=token, answer=result, time=t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlLnZM7hi0C2"
      },
      "source": [
        "## 1c) Opcional: Entropía Cruzada Categórica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qj1GI81izYt"
      },
      "source": [
        "# No es necesario que entregues código en esta parte.\n",
        "# Pero si quieres, igual hay espacio ;-)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwedMCZjXDSw"
      },
      "source": [
        "# Parte 2: Más derivadas y back propagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nftKKxlBXDSx"
      },
      "source": [
        "## 2a) Derivando la última capa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDBD96xWXDSx"
      },
      "source": [
        "Escribe tu cálculo acá.\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial \\cal L}{\\partial u^{(L+1)}} =\n",
        "\\end{equation}\n",
        "<br>\n",
        "(No es necesario que repitas el código que era solo de ayuda para chequear las dimensiones.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzp5SWKBXDSy"
      },
      "source": [
        "## 2b) Derivando la última capa (continuación)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9cubvpeXDSz"
      },
      "source": [
        "Escribe tus respuestas acá.\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial\\cal L}{\\partial U} = \\ldots \\\\\n",
        "\\end{equation}\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial\\cal L}{\\partial c} = \\ldots \\\\\n",
        "\\end{equation}\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial\\cal L}{\\partial h^{(L)}} = \\ldots \\\\\n",
        "\\end{equation}\n",
        "<br>\n",
        "(No es necesario que repitas el código que era solo de ayuda para chequear las dimensiones.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WNYoTIHXDS0"
      },
      "source": [
        "## 2c) Derivando desde las capas escondidas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz7TChQ8XDS0"
      },
      "source": [
        "Escribe tus respuestas acá. Repite los siguientes cálculos para $\\text{relu}, \\text{celu}, \\text{swish}$\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial\\cal L}{\\partial u^{(k)}} = \\ldots \\\\\n",
        "\\end{equation}\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial\\cal L}{\\partial W^{(k)}} = \\ldots \\\\\n",
        "\\end{equation}\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial\\cal L}{\\partial b^{(k)}} = \\ldots \\\\\n",
        "\\end{equation}\n",
        "<br>\n",
        "\n",
        "\\begin{equation}\n",
        "\\frac{\\partial\\cal L}{\\partial h^{(k-1)}} = \\ldots \\\\\n",
        "\\end{equation}\n",
        "<br>\n",
        "(No es necesario que repitas el código que era solo de ayuda para chequear las dimensiones.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n29s-6zXDS1"
      },
      "source": [
        "# Parte 3: Backpropagation en nuestra red"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do04-nhfXDS2"
      },
      "source": [
        "## 3a) Método `backward` + parte 3b) Opcional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytN2y-FMXDS3"
      },
      "source": [
        "# Acá solo deberías programar la función backward.\n",
        "# El resto del código viene de la Tarea 1 (a menos que hayas programado\n",
        "# la parte opcional en cuyo caso también deberías cambiar el inicializador).\n",
        "# Puedes incluir todo el código de la Tarea 1 que quieras.\n",
        "class FFNN(torch.nn.Module):\n",
        "  # código desde la Tarea 1\n",
        "  def __init__(self, F, l_h, l_a, C):\n",
        "    super(FFNN, self).__init__()\n",
        "    pass\n",
        "\n",
        "  # código desde la Tarea 1\n",
        "  def load_weights(self, Ws, U, bs, c):\n",
        "    pass\n",
        "\n",
        "  # código desde la Tarea 1\n",
        "  def resumen(self):\n",
        "    pass\n",
        "  \n",
        "  # código desde la Tarea 1\n",
        "  def forward(self, x):\n",
        "    pass\n",
        "\n",
        "  # nuevo código Tarea 2\n",
        "  def backward(self, x, y, y_pred):\n",
        "    # Computar acá todos los gradientes con respecto a L\n",
        "    # Hint: Los gradientes deben quedar almacenados en \n",
        "    #       el atributo `grad` para cada parámetro.\n",
        "    #       Más info sobre este atributo en\n",
        "    #       https://pytorch.org/docs/stable/autograd.html#torch.Tensor.grad\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S3suoQ2tZfX"
      },
      "source": [
        "# Tests del API del curso\n",
        "# (estos Tests NO sustituyen al anterior en la verificación de los gradientes)\n",
        "for test in ['mnist-model']:\n",
        "  # Obtenemos los parámetos de la red desde el API\n",
        "  F, l_h, l_a, C, Ws, U, bs, c, X, y = corrector.get_test_data(homework=2, question=\"3a\", test=test, token=token)\n",
        "  l_a = [f for s in l_a for f in [sig, tanh, relu, celu] if f.__name__ == s]\n",
        "\n",
        "  # Inicializamos modelo con parámetros del API\n",
        "  your_model = FFNN(F=F, l_h=l_h, l_a=l_a, C=C)\n",
        "  your_model.load_weights([torch.Tensor(l) for l in Ws], torch.Tensor(U), [torch.Tensor(l) for l in bs], torch.Tensor(c))\n",
        "  \n",
        "  # Obtenemos el índice del parámetro Ws[1] en la lista de parámetros de tu modelo\n",
        "  idx = next(i for i, p in enumerate(your_model.parameters()) if p.size() == torch.Tensor(Ws[1]).size() and torch.all(torch.Tensor(Ws[1])==p))\n",
        "\n",
        "  # Ejecutemos el forward de para input del API\n",
        "  y_pred = your_model(torch.Tensor(X))\n",
        "  \n",
        "  # Ejecutemos el backward de tu modelo para ver como se comporta\n",
        "  s = timer()\n",
        "  your_model.backward(torch.Tensor(X), torch.Tensor(y), y_pred)\n",
        "  t = timer() - s\n",
        "  \n",
        "  # Veamos todo fue OK :)\n",
        "  # Si el Test te falla algunas veces por [time], puedes hacer time=0 ;-)\n",
        "  corrector.sumbit(homework=2, question=\"3a\", test=test, token=token, \n",
        "                   answer=list(your_model.parameters())[idx].grad.mean(), time=t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6_7qOkAlcTX"
      },
      "source": [
        "## 3c) Opcional: Chequeo de gradiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjfsSKLIlgKj"
      },
      "source": [
        "# No es necesario que entregues código en esta parte dado \n",
        "# que solo es necesario para debuggear que tu implementación está correcta.\n",
        "# Pero si quieres, igual hay espacio ;-)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDSYiQQ6nkjX"
      },
      "source": [
        "# Parte 4: Descenso de gradiente y optimización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqBwusuXnsjO"
      },
      "source": [
        "## 4a) Descenso de gradiente (estocástico)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tId-cHk7ntDW"
      },
      "source": [
        "# Tu código debiera comenzar así\n",
        "\n",
        "class SGD():\n",
        "  def __init__(self, parameters, lr):\n",
        "    # lo que sea necesario inicializar\n",
        "    pass\n",
        "  \n",
        "  def step(self):\n",
        "    # actualiza acá los parámetros a partir del gradiente de cada uno\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN9Bh70SJGgI"
      },
      "source": [
        "# Tests del API del curso\n",
        "from torch.nn import Parameter\n",
        "for test in ['small-step', 'big-step', 'random']:\n",
        "  # Obtengamos una lista de parámetros (con gradientes en .grad) y un valor lr\n",
        "  ds, gs, lr, idx = corrector.get_test_data(homework=2, question=\"4a\", test=test, token=token)\n",
        "  parameters = [Parameter(torch.Tensor(d)) for d in ds]\n",
        "  for p, g in zip(parameters, gs):\n",
        "    p.grad = torch.Tensor(g)\n",
        "\n",
        "  # Inicialicemos tu SGD\n",
        "  optimizer = SGD(parameters, lr)\n",
        "\n",
        "  # Ejecutemos un paso de tu SGD para ver como se comporta\n",
        "  s = timer()\n",
        "  optimizer.step()\n",
        "  t = timer() - s\n",
        "\n",
        "  # Veamos si todo fue OK :)\n",
        "  # Si el Test te falla algunas veces por [time], puedes hacer time=0 ;-)\n",
        "  corrector.sumbit(homework=2, question=\"4a\", test=test, token=token, \n",
        "                   answer=parameters[idx].data, time=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy0KFSX4nzP0"
      },
      "source": [
        "## 4b) Datos para carga"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bByG7kXlnwAQ"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Aquí tu código.\n",
        "# Tu clase debiera verse así\n",
        "class RandomDataset(Dataset):\n",
        "  def __init__(self, N, F, C):\n",
        "    pass\n",
        "  \n",
        "  def __len__(self):\n",
        "    pass\n",
        "  \n",
        "  def __getitem__(self, i):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x49Wy06IsJDU"
      },
      "source": [
        "# Inicialicemos un RandomDataset de prueba\n",
        "N,F,C=100,300,10\n",
        "your_dataset = ...\n",
        "\n",
        "# Veamos como se comportan __len__ y __getitem__\n",
        "print(\"Correct Test!\" if len(your_dataset) == N else \"Failed Test [len]\") \n",
        "print(\"Correct Test!\" if type(your_dataset[N//2]) == tuple and len(your_dataset[N//3]) == 2 else \"Failed Test [getitem]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-q8vJOMn3AA"
      },
      "source": [
        "## 4c) Optimizando los parámetros de la red para datos al azar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap0AKJijn5DY"
      },
      "source": [
        "# Tu código acá\n",
        "def entrenar_FFNN(red, dataset, optimizador, epochs=1, batch_size=1, device='cuda'):\n",
        "  red.to(...)\n",
        "  \n",
        "  # Inicialicemos un DataLoader para los ejemplos de dataset\n",
        "  data = ...\n",
        "\n",
        "  # Comienza el entrenamiento\n",
        "  loss, acc = [], []\n",
        "  for e in range(1,epochs+1):\n",
        "    for x, y in data:\n",
        "      pass\n",
        "\n",
        "  return loss, acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0VbGtY5aWLk"
      },
      "source": [
        "dataset = ...\n",
        "model = ...\n",
        "optimizer = ...\n",
        "with torch.no_grad():\n",
        "  loss, acc = entrenar_FFNN(model, dataset, optimizer, ...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDnYdhV0n_X-"
      },
      "source": [
        "## 4d) Graficando la pérdida/error en el tiempo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oufOfvyIRvAT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results(loss, acc):\n",
        "  # Muestra dos figuras: \n",
        "  #  (1) gráfico para la lista `loss` (Loss) y \n",
        "  #  (2) gráfico para la lista `acc` (Accuracy)\n",
        "\n",
        "  f1 = plt.figure(1)\n",
        "  ax1 = f1.add_subplot(111)\n",
        "  ax1.set_title(\"Loss\")    \n",
        "  ax1.set_xlabel('epochs')\n",
        "  ax1.set_ylabel('loss')\n",
        "  ax1.plot(loss, c='r')\n",
        "  f1.show()\n",
        "\n",
        "  f2 = plt.figure(2)\n",
        "  ax2 = f2.add_subplot(111)\n",
        "  ax2.set_title(\"Accuracy\")    \n",
        "  ax2.set_xlabel('epochs')\n",
        "  ax2.set_ylabel('acc')\n",
        "  ax2.plot(acc, c='b')\n",
        "  f2.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVhVgf1poBkQ"
      },
      "source": [
        "# Tu código acá"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICCODVV9oF9d"
      },
      "source": [
        "## 4e) Opcional: Optimizando tu red para MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cRIuWQroDW9"
      },
      "source": [
        "# Tu código de carga de datos, creación de la red, \n",
        "# entrenamiento/optimización y reportes acá"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}